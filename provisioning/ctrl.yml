- hosts: controller
  become: true
  tasks:

  # --------- STEP 16: Install Helm ---------
  - name: Define Helm install script URL and temporary path (step 16)
    ansible.builtin.set_fact:
      helm_script_url: "https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3"
      helm_script_path: "/home/vagrant/get_helm.sh"

  - name: Check if Helm binary exists (step 16)
    ansible.builtin.stat:
      path: /usr/local/bin/helm
    register: helm_binary_stat

  - name: Download Helm install script (step 16)
    ansible.builtin.get_url:
      url: "{{ helm_script_url }}"
      dest: "{{ helm_script_path }}"
      mode: '0755'
    become: false
    when: not helm_binary_stat.stat.exists

  - name: Install Helm if not present (step 16)
    async: 120
    poll: 0
    register: install_helm_async_task
    ansible.builtin.command:
      cmd: "{{ helm_script_path }}"
      creates: /usr/local/bin/helm
    become: true
    when: not helm_binary_stat.stat.exists

  #download kubernetes library (needed for step 15)
  - name: Ensure Kubernetes Python client is installed
    apt:
      name: python3-kubernetes
      state: present

  # --------- STEP 13: Init cluster ---------
  - name: Check for admin.conf (step 13)
    ansible.builtin.stat:
      path: /etc/kubernetes/admin.conf
    register: admin_conf_stat # Store the result

  - name: Conditional kubeadm reset (step 13)
    ansible.builtin.command: kubeadm reset -f
    when: 
      - not admin_conf_stat.stat.exists
      - "'ctrl' in group_names"
    ignore_errors: yes
    register: reset_stat
    changed_when: reset_stat.rc == 0

  - name: Cluster initialization using kubeadm (step 13)
    ansible.builtin.shell:
      cmd: >
        kubeadm init
        --apiserver-advertise-address=192.168.56.100
        --node-name ctrl
        --pod-network-cidr=10.244.0.0/16
    register: init_result
    when: not admin_conf_stat.stat.exists

  # Verify
  - name: Wait until Kubernetes admin.conf is available (step 13)
    ansible.builtin.wait_for:
      path: /etc/kubernetes/admin.conf
      state: present
      timeout: 60
    when: admin_conf_stat.stat.exists or init_result is succeeded

  - name: Poll Kubernetes API server until it's ready (step 13)
    ansible.builtin.uri:
      url: https://localhost:6443/healthz
      method: GET
      validate_certs: no
    register: api_health
    until: api_health.status == 200
    retries: 10
    delay: 6
    changed_when: false   

  # --------- STEP 14: Setup kubectl ---------
  - name: Create .kube directory for vagrant user (step 14)
    ansible.builtin.file:
      path: "/home/vagrant/.kube/"
      state: directory
      owner: vagrant
      group: vagrant
      mode: "0700"

  - name: Copy admin.conf to vagrant user's .kube directory (step 14)
    ansible.builtin.copy:
      src: /etc/kubernetes/admin.conf
      dest: /home/vagrant/.kube/config
      remote_src: yes
      owner: vagrant
      group: vagrant
      mode: "0600"

  - name: Fetch admin.conf from controller to host machine (step 14)
    ansible.builtin.fetch:
      src: /etc/kubernetes/admin.conf
      dest: "{{ playbook_dir }}/config/"
      flat: yes

  - name: Display info about using the fetched kubeconfig (step 14)
    ansible.builtin.debug:
      msg: |
        ----------------------------------------------------------------------
        KUBECONFIG for host access has been fetched to: {{ playbook_dir }}/config/admin.conf
        You can use it with:
        export KUBECONFIG={{ playbook_dir }}/config/admin.conf
        or
        kubectl --kubeconfig={{ playbook_dir }}/config/admin.conf get nodes
        ----------------------------------------------------------------------

  # --------- STEP 15: Create Pod Network ---------
  - name: Ensure resources/ dir exists on controller
    delegate_to: localhost
    connection: local
    become: false
    run_once: true
    ansible.builtin.file:
      path: "{{ playbook_dir }}/resources"
      state: directory
      mode: '0755'

  - name: Check for local Flannel manifest
    delegate_to: localhost
    connection: local      # run it directly, no SSH
    become: false          # donâ€™t try sudo on localhost
    run_once: true
    ansible.builtin.stat:
      path: "{{ playbook_dir }}/resources/kube-flannel.yml"
    register: flannel_manifest

  - name: Download Flannel manifest if not found locally
    delegate_to: localhost
    connection: local
    become: false
    run_once: true
    ansible.builtin.get_url:
      url: "https://github.com/flannel-io/flannel/releases/download/v0.26.7/kube-flannel.yml"
      dest: "{{ playbook_dir }}/resources/kube-flannel.yml"
      mode: '0644'
    when: not flannel_manifest.stat.exists

  - name: Copy Flannel manifest into the VM (step 15)
    ansible.builtin.copy:
      src: "{{ playbook_dir }}/resources/kube-flannel.yml"
      dest: "/home/vagrant/kube-flannel.yml"
      owner: vagrant
      group: vagrant
      mode: '0644'

  - name: Set flannel_path (step 15)
    ansible.builtin.set_fact:
      flannel_path: "/home/vagrant/kube-flannel.yml"
  
  - name: Assign NIC for cluster communication (step 15)
    ansible.builtin.lineinfile:
      path: "{{ flannel_path }}"
      insertafter: '^\s*- --kube-subnet-mgr'
      line: '        - --iface=eth1'
      firstmatch: true # Apply the change only to the first match found in the file
    become: false

  - name: Apply Flannel manifest using Ansible module (step 15)
    kubernetes.core.k8s:
      state: present
      src: "{{ flannel_path }}"
      kubeconfig: /home/vagrant/.kube/config

  - name: Retrieve async task ID of helm installation task if it is still running
    ansible.builtin.stat:
      path: "/root/.ansible_async/{{ install_helm_async_task.ansible_job_id }}"
    register: helm_job_id_check

  - name: Wait for helm installation async task to complete
    ansible.builtin.async_status:
      jid: "{{ install_helm_async_task.ansible_job_id }}"
    when: helm_job_id_check.stat.exists
    register: helm_async_task_result
    until: helm_async_task_result.finished
    retries: 60
    delay: 1
    ignore_errors: true

  # --------- STEP 17: Install Helm Diff Plugin ---------
  - name: Download and install helm-diff if not already present (step 17)
    async: 120
    poll: 0
    register: install_helm_diff_async_task
    ansible.builtin.command: >
      helm plugin install https://github.com/databus23/helm-diff
    args:
      creates: /home/vagrant/.local/share/helm/plugins/helm-diff
    become_user: vagrant
    environment:
      KUBECONFIG: ""
      HELM_KUBECONFIG: ""

  - name: Clean up Helm install script (step 16)
    ansible.builtin.file:
      path: "{{ helm_script_path }}"
      state: absent
    become: false

  - name: Retrieve async task ID of helm diff installation task if it is still running
    ansible.builtin.stat:
      path: "/root/.ansible_async/{{ install_helm_diff_async_task.ansible_job_id }}"
    register: helm_diff_job_id_check

  - name: Wait for helm diff installation async task to complete
    ansible.builtin.async_status:
      jid: "{{ install_helm_diff_async_task.ansible_job_id }}"
    when: helm_diff_job_id_check.stat.exists
    register: helm_diff_async_task_result
    until: helm_diff_async_task_result.finished
    retries: 120
    delay: 1
    ignore_errors: true

  - name:  Verify Flannel is running (step 15)
    ansible.builtin.shell: |
      kubectl --kubeconfig=/home/vagrant/.kube/config get pods -n kube-flannel -o custom-columns=STATUS:.status.phase --no-headers | grep -c "Running" | grep -q "^[1-9]"
    register: flannel_check
    until: flannel_check.rc == 0
    retries: 60
    delay: 1
    changed_when: false
    ignore_errors: true


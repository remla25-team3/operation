- name: Finalization
  hosts: all
  become: true
  vars_files:
    - vars/all.yml
  tasks:

  #step 20
  - name: Ensure resources/ dir exists
    delegate_to: localhost
    connection: local
    become: false
    run_once: true
    ansible.builtin.file:
      path: "{{ playbook_dir }}/resources"
      state: directory
      mode: '0755'

  - name: Check for local MetalLB manifest
    delegate_to: localhost
    connection: local      # run it directly, no SSH
    become: false          # don't try sudo on localhost
    run_once: true
    ansible.builtin.stat:
      path: "{{ playbook_dir }}/resources/metallb-native.yaml"
    register: metallb_manifest

  - name: Download MetalLB manifest if not found locally (step 20)
    delegate_to: localhost
    connection: local
    become: false
    run_once: true
    get_url:
      url: https://raw.githubusercontent.com/metallb/metallb/v0.14.9/config/manifests/metallb-native.yaml
      dest: "{{ playbook_dir }}/resources/metallb-native.yaml"
      mode: '0644'
    when: not metallb_manifest.stat.exists

  - name: Copy MetalLB manifest to controller
    copy:
      src: "{{ playbook_dir }}/resources/metallb-native.yaml"
      dest: /tmp/metallb-native.yaml
      mode: '0644'

  - name: Deploy MetalLB using official manifest (step 20)
    kubernetes.core.k8s:
      state: present
      src: /tmp/metallb-native.yaml
      kubeconfig: "{{ kubeconfig }}"

  - name: Remove NoSchedule taints from controller node (step 20)
    shell: |
      kubectl taint nodes ctrl node-role.kubernetes.io/control-plane:NoSchedule- || true
      kubectl taint nodes ctrl node-role.kubernetes.io/master:NoSchedule- || true
    changed_when: false

  - name: Wait for MetalLB controller pod to become ready (step 20)
    shell: |
      kubectl wait -n metallb-system -l app=metallb,component=controller --for=condition=ready pod --timeout=60s --kubeconfig={{ kubeconfig }}
    changed_when: false

  - name: Create IPAddressPool manifest for MetalLB (step 20)
    copy:
      dest: /tmp/metallb-pool.yaml
      mode: '0644'
      content: |
        apiVersion: metallb.io/v1beta1
        kind: IPAddressPool
        metadata:
          name: remla-pool
          namespace: metallb-system
        spec:
          addresses:
            - {{ ip_range }}

  - name: Apply IPAddressPool manifest (step 20)
    kubernetes.core.k8s:
      state: present
      src: /tmp/metallb-pool.yaml
      kubeconfig: "{{ kubeconfig }}"

  - name: Create L2Advertisement manifest for MetalLB (step 20)
    copy:
      dest: /tmp/metallb-l2adv.yaml
      mode: '0644'
      content: |
        apiVersion: metallb.io/v1beta1
        kind: L2Advertisement
        metadata:
          name: remla-l2
          namespace: metallb-system
        spec:
          ipAddressPools:
            - remla-pool

  - name: Apply L2Advertisement manifest (step 20)
    kubernetes.core.k8s:
      state: present
      src: /tmp/metallb-l2adv.yaml
      kubeconfig: "{{ kubeconfig }}"

  #step 21
  - name: Add ingress-nginx Helm repository (step 21)
    kubernetes.core.helm_repository:
      name: ingress-nginx
      repo_url: https://kubernetes.github.io/ingress-nginx
      kubeconfig: "{{ kubeconfig }}"

  - name: Install ingress-nginx with static LoadBalancer IP (step 21)
    kubernetes.core.helm:
      name: ingress-nginx
      chart_ref: ingress-nginx/ingress-nginx
      chart_version: "4.11.0"
      release_namespace: ingress-nginx
      create_namespace: true
      kubeconfig: "{{ kubeconfig }}"
      values:
        controller:
          service:
            type: LoadBalancer
            loadBalancerIP: "{{ ingress_ip }}"
          ingressClassResource:
            name: nginx
          ingressClass: nginx
  
  - name: Wait for NGINX Ingress controller pod to become ready (step 21)
    shell: |
      kubectl --kubeconfig={{ kubeconfig }} wait -n ingress-nginx \
      --for=condition=ready pod \
      -l app.kubernetes.io/name=ingress-nginx,app.kubernetes.io/component=controller \
      --timeout=120s
    changed_when: false

  #step 22
  - name: Add Kubernetes Dashboard Helm repo (step 22)
    kubernetes.core.helm_repository:
      name: kubernetes-dashboard
      repo_url: https://kubernetes.github.io/dashboard
      kubeconfig: "{{ kubeconfig }}"

  - name: Install Kubernetes Dashboard via Helm (step 22)
    kubernetes.core.helm:
      name: "{{ dashboard_release }}"
      chart_ref: kubernetes-dashboard/kubernetes-dashboard
      release_namespace: "{{ dashboard_namespace }}"
      create_namespace: true
      kubeconfig: "{{ kubeconfig }}"
      force: true

  - name: Create admin-user ServiceAccount and ClusterRoleBinding (step 22)
    copy:
      dest: /tmp/dashboard-adminuser.yaml
      mode: '0644'
      content: |
        apiVersion: v1
        kind: ServiceAccount
        metadata:
          name: admin-user
          namespace: {{ dashboard_namespace }}
        ---
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRoleBinding
        metadata:
          name: admin-user
        roleRef:
          apiGroup: rbac.authorization.k8s.io
          kind: ClusterRole
          name: cluster-admin
        subjects:
          - kind: ServiceAccount
            name: admin-user
            namespace: {{ dashboard_namespace }}

  - name: Apply admin-user access (step 22)
    kubernetes.core.k8s:
      state: present
      src: /tmp/dashboard-adminuser.yaml
      kubeconfig: "{{ kubeconfig }}"

  - name: Create Ingress for Dashboard (step 22)
    copy:
      dest: /tmp/dashboard-ingress.yaml
      mode: '0644'
      content: |
        apiVersion: networking.k8s.io/v1
        kind: Ingress
        metadata:
          name: kubernetes-dashboard
          namespace: {{ dashboard_namespace }}
          annotations:
            nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
            nginx.ingress.kubernetes.io/ssl-redirect: "true"
            nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
        spec:
          ingressClassName: nginx
          tls:
            - hosts:
                - {{ ingress_host }}
          rules:
            - host: {{ ingress_host }}
              http:
                paths:
                  - path: /
                    pathType: Prefix
                    backend:
                      service:
                        name: kubernetes-dashboard-kong-proxy
                        port:
                          number: 443

  - name: Apply Dashboard Ingress (step 22)
    kubernetes.core.k8s:
      state: present
      src: /tmp/dashboard-ingress.yaml
      kubeconfig: "{{ kubeconfig }}"

  - name: Wait for Dashboard proxy service to become available (step 22)
    shell: |
      kubectl wait --namespace={{ dashboard_namespace }} \
        --for=condition=ready pod \
        -l app.kubernetes.io/instance={{ dashboard_release }} \
        --timeout=300s --kubeconfig={{ kubeconfig }}
    changed_when: false

  - name: Display dashboard instructions (step 22)
    debug:
      msg:
        - "Kubernetes Dashboard deployed and accessible via Ingress."
        - ""
        - "To access it, follow these steps:"
        - ""
        - "1. Open your terminal on the host machine and run:"
        - "  sudo nano /etc/hosts"
        - ""
        - "2. Add the following line to the bottom of the file:"
        - "  {{ ingress_ip }}   dashboard.local"
        - ""
        - "3. Save and exit nano:"
        - "  Press Ctrl + O (to write the file), then Enter, then Ctrl + X (to exit)"
        - ""
        - "4. Open your browser and visit:"
        - "  https://dashboard.local"
        - ""
        - "5. To log in, run the following command on the controller VM to generate a token:"
        - "  vagrant ssh ctrl"
        - "  kubectl -n {{ dashboard_namespace }} create token admin-user"
        - ""
        - "6. Paste the token into the Dashboard login screen."

  - name: Remove NoSchedule taints from all nodes
    shell: |
      kubectl taint nodes --all node-role.kubernetes.io/control-plane:NoSchedule- || true
      kubectl taint nodes --all node-role.kubernetes.io/master:NoSchedule- || true
    changed_when: false

  # -----------------STEP 23: Install Istio-----------------

  - name: Add Istio (step 23)
    ansible.builtin.unarchive:
      src: https://github.com/istio/istio/releases/download/1.25.2/istio-1.25.2-linux-arm64.tar.gz
      dest: /usr/local/bin
      remote_src: yes
      mode: 'u=rX'

  - name: Set user permissions for istioctl command (step 23)
    ansible.builtin.file:
      path: /usr/local/bin/istio-1.25.2
      state: directory
      recurse: yes
      owner: vagrant
      group: vagrant
      mode: 'u=rX'

  - name: Get contents of PATH (step 23)
    command: cat /etc/environment
    register: path_contents

  - name: Add PATH line if it did not exist in /etc/environment (step 23)
    ansible.builtin.lineinfile:
      path: /etc/environment
      line: 'PATH=""'
      insertafter: EOF
      state: present
      create: true
    when: not path_contents|regex_search('\s*PATH=.*')

  - name: Add istioctl to PATH (step 23)
    ansible.builtin.lineinfile:
      path: /etc/environment
      regexp: "^PATH=(\"?)([^\"]*)(\"?)$"
      line: 'PATH=\1\2:/usr/local/bin/istio-1.25.2/bin\3'
      backrefs: yes
    when: not path_contents|regex_search('istio-1.25.2')

  - name: Copy Istio configuration file to node (step 23)
    copy:
      src: "{{ playbook_dir }}/istio-config.yml"
      dest: /tmp/istio-config.yml
      mode: '0644'

  - name: Run istio installation on controller node (step 23)
    command: istioctl install -f /tmp/istio-config.yml
    when: ansible_hostname == 'controller'

#  - name: Add Istio Helm repository (step 23)
#    kubernetes.core.helm_repository:
#      name: istio
#      repo_url: https://istio-release.storage.googleapis.com/charts
#      kubeconfig: "{{ kubeconfig }}"
#
#  - name: Create namespace istio-system (step 23)
#    kubernetes.core.k8s:
#      kubeconfig: "{{ kubeconfig }}"
#      state: present
#      definition:
#        apiVersion: v1
#        kind: Namespace
#        metadata:
#          name: istio-system
#
#  - name: Install Istio base chart (CRDs) (step 23)
#    kubernetes.core.helm:
#      release_name: istio-base
#      chart_ref: istio/base
#      chart_version: "1.25.2"
#      release_namespace: istio-system
#      create_namespace: false
#      kubeconfig: "{{ kubeconfig }}"
#      wait: true
#
#  - name: Install Istio control plane (istiod) (step 23)
#    kubernetes.core.helm:
#      release_name: istiod
#      chart_ref: istio/istiod
#      chart_version: "1.25.2"
#      release_namespace: istio-system
#      create_namespace: false
#      kubeconfig: "{{ kubeconfig }}"
#      wait: true
#      timeout: "300s"
#      values:
#        pilot:
#          resources:
#            # shrink requests so istiod can schedule on low‐RAM nodes (too heave otherwise, might need to be changed in the future)
#            requests:
#              cpu: "100m"
#              memory: "128Mi"
#            limits:
#              cpu: "200m"
#              memory: "256Mi"
#
#  - name: Deploy Istio ingress gateway with fixed IP (step 23)
#    kubernetes.core.helm:
#      release_name: istio-ingress
#      chart_ref: istio/gateway
#      chart_version: "1.25.2"
#      release_namespace: istio-system
#      create_namespace: false
#      kubeconfig: "{{ kubeconfig }}"
#      wait: true
#      timeout: "300s"
#      values:
#        gateways:
#          istio-ingressgateway:
#            enabled: true
#            service:
#              type: LoadBalancer
#              loadBalancerIP: "{{ istio_ip }}"
#            podAnnotations:
#              sidecar.istio.io/inject: "false"
#
#  - name: Istio deployment summary (step 23)
#    debug:
#      msg:
#        - "Istio has been successfully installed using Helm."
#        - "Your cluster is now prepared for Istio-based deployments."
    
#Assignment 3
- import_playbook: monitoring-alerting.yml
